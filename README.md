# üõí Shopping Monitor

Outil de monitoring Google Shopping avec approche projet-centric pour comparer performance vs concurrents.

## üéØ Fonctionnalit√©s

- **Monitoring multi-projets** : Organisez vos campagnes par projet
- **Tracking concurrentiel** : Surveillez vos concurrents automatiquement  
- **Analytics avanc√©es** : Part de voix, matrice de positions, opportunit√©s
- **API DataForSEO** : Donn√©es SERP Google Shopping en temps r√©el
- **Dashboard interactif** : Interface React moderne
- **Architecture √©volutive** : FastAPI + PostgreSQL + Redis

## üèóÔ∏è Architecture

### Backend
- **FastAPI** : API REST haute performance
- **SQLAlchemy** : ORM avec support async
- **PostgreSQL** : Base de donn√©es principale
- **Redis** : Cache et sessions
- **Alembic** : Migrations de base de donn√©es

### Frontend  
- **React** : Interface utilisateur moderne
- **Chart.js/Recharts** : Visualisations de donn√©es
- **Material-UI** : Composants UI

## üöÄ Installation

### Pr√©requis

- Python 3.11+
- Node.js 18+
- Docker & Docker Compose (recommand√©)
- PostgreSQL 15+ (si installation locale)
- Redis 7+ (si installation locale)

### 1. Cloner le projet

```bash
git clone <repository-url>
cd shopping-monito
```

### 2. Configuration environnement

```bash
cp env.example .env
# √âditer .env avec vos configurations
```

### 3. Installation avec Docker (Recommand√©)

```bash
# D√©marrer PostgreSQL et Redis
docker-compose up postgres redis

# Ou avec pgAdmin pour la gestion DB
docker-compose --profile tools up postgres redis pgadmin
```

### 4. Installation locale

```bash
# Backend
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou venv\Scripts\activate  # Windows

pip install -r requirements.txt

# Frontend (dans un autre terminal)
cd frontend
npm install
```

## üóÑÔ∏è Base de donn√©es

### Migrations avec Alembic

```bash
# Cr√©er une migration
alembic revision --autogenerate -m "Description"

# Appliquer les migrations
alembic upgrade head

# Revenir en arri√®re
alembic downgrade -1
```

### Structure des tables

```sql
-- Projets (entit√© principale)
projects (id, name, description, created_at, updated_at, is_active)

-- Concurrents par projet  
competitors (id, project_id, name, domain, brand_name, is_main_brand)

-- Mots-cl√©s par projet
keywords (id, project_id, keyword, location, language, search_volume, is_active)

-- R√©sultats SERP (donn√©es DataForSEO)
serp_results (id, project_id, keyword_id, competitor_id, position, price, rating, ...)

-- URLs uniques (d√©duplication)
unique_urls (id, url, domain, product_data, scraping_status)
```

## üîß Configuration

### Variables d'environnement (.env)

```bash
# Base de donn√©es
DATABASE_URL=postgresql+asyncpg://user:password@localhost:5432/shopping_monitor
DATABASE_URL_SYNC=postgresql://user:password@localhost:5432/shopping_monitor

# Redis
REDIS_URL=redis://localhost:6379/0

# DataForSEO API
DATAFORSEO_LOGIN=your_login
DATAFORSEO_PASSWORD=your_password

# FastAPI
SECRET_KEY=your-super-secret-key
DEBUG=True
ENVIRONMENT=development
```

## üö¶ D√©marrage

### Avec Docker

```bash
# Services uniquement (DB + Redis)
docker-compose up postgres redis

# Application compl√®te
docker-compose --profile full up

# Avec outils de d√©veloppement
docker-compose --profile tools up
```

### Installation locale

```bash
# Backend (terminal 1)
source venv/bin/activate
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# Frontend (terminal 2) 
cd frontend
npm start
```

## üìä Utilisation

### 1. Cr√©er un projet

```bash
curl -X POST "http://localhost:8000/api/v1/projects" \
  -H "Content-Type: application/json" \
  -d '{
    "name": "Mon Projet E-commerce",
    "description": "Monitoring produits √©lectronique"
  }'
```

### 2. Ajouter des concurrents

```bash
curl -X POST "http://localhost:8000/api/v1/projects/{project_id}/competitors" \
  -H "Content-Type: application/json" \
  -d '{
    "name": "Amazon",
    "domain": "amazon.fr",
    "brand_name": "Amazon",
    "is_main_brand": false
  }'
```

### 3. Ajouter des mots-cl√©s

```bash
curl -X POST "http://localhost:8000/api/v1/projects/{project_id}/keywords" \
  -H "Content-Type: application/json" \
  -d '{
    "keyword": "smartphone samsung",
    "location": "France",
    "language": "fr"
  }'
```

### 4. Lancer le scraping

```bash
curl -X POST "http://localhost:8000/api/v1/projects/{project_id}/scrape"
```

## üìà Analytics

### Endpoints disponibles

- `GET /api/v1/projects/{id}/dashboard` - M√©triques globales
- `GET /api/v1/projects/{id}/share-of-voice` - Part de voix
- `GET /api/v1/projects/{id}/position-matrix` - Matrice positions
- `GET /api/v1/projects/{id}/opportunities` - Opportunit√©s manqu√©es
- `GET /api/v1/projects/{id}/competitor-comparison` - Comparatif
- `GET /api/v1/projects/{id}/trend-analysis` - Analyses tendances

### M√©triques calcul√©es

- **Part de voix** : % d'apparitions vs concurrents
- **Score de visibilit√©** : Pond√©ration position √ó volume recherche
- **Position moyenne** : Moyenne des positions sur tous les mots-cl√©s
- **Comp√©titivit√© prix** : Positionnement prix vs march√©

## üîå API DataForSEO

### Configuration

1. Cr√©er un compte sur [DataForSEO](https://dataforseo.com/)
2. R√©cup√©rer vos identifiants API
3. Les ajouter dans `.env`

### Endpoints utilis√©s

- `serp/google/shopping/live/advanced` - SERP Google Shopping
- `keywords_data/google/search_volume/live` - Volume de recherche

## üß™ Tests

```bash
# Tests unitaires
pytest

# Tests avec coverage
pytest --cov=app --cov-report=html

# Tests d'int√©gration
pytest tests/integration/

# Tests de charge
pytest tests/load/
```

## üìù D√©veloppement

### Structure du projet

```
shopping-monito/
‚îú‚îÄ‚îÄ app/                    # Backend FastAPI
‚îÇ   ‚îú‚îÄ‚îÄ models/            # Mod√®les SQLAlchemy
‚îÇ   ‚îú‚îÄ‚îÄ schemas/           # Schemas Pydantic
‚îÇ   ‚îú‚îÄ‚îÄ api/               # Routes FastAPI
‚îÇ   ‚îú‚îÄ‚îÄ services/          # Logique m√©tier
‚îÇ   ‚îú‚îÄ‚îÄ core/              # Utilitaires
‚îÇ   ‚îî‚îÄ‚îÄ main.py            # Point d'entr√©e
‚îú‚îÄ‚îÄ frontend/              # Application React
‚îú‚îÄ‚îÄ alembic/               # Migrations DB
‚îú‚îÄ‚îÄ tests/                 # Tests
‚îú‚îÄ‚îÄ docker-compose.yml     # Services Docker
‚îî‚îÄ‚îÄ requirements.txt       # D√©pendances Python
```

### Conventions de code

- **Python** : Black, isort, flake8, mypy
- **JavaScript** : ESLint, Prettier
- **Commits** : Conventional Commits
- **Branches** : GitFlow

### Ajout d'une nouvelle fonctionnalit√©

1. Cr√©er une branche `feature/nom-fonctionnalite`
2. Ajouter les mod√®les SQLAlchemy si n√©cessaire
3. Cr√©er les schemas Pydantic
4. Impl√©menter les services m√©tier
5. Ajouter les routes API
6. √âcrire les tests
7. Mettre √† jour la documentation

## üöÄ D√©ploiement

### Production

```bash
# Build des images
docker-compose -f docker-compose.prod.yml build

# D√©ploiement
docker-compose -f docker-compose.prod.yml up -d

# Migrations
docker-compose exec api alembic upgrade head
```

### Variables d'environnement production

```bash
ENVIRONMENT=production
DEBUG=False
SECRET_KEY=<strong-secret-key>
DATABASE_URL=<production-db-url>
REDIS_URL=<production-redis-url>
```

## üìö Documentation

- **API** : http://localhost:8000/docs (Swagger)
- **ReDoc** : http://localhost:8000/redoc
- **pgAdmin** : http://localhost:5050 (si activ√©)

## ü§ù Contribution

1. Fork du projet
2. Cr√©er une branche feature
3. Commits avec messages clairs
4. Tests pour les nouvelles fonctionnalit√©s
5. Pull request avec description d√©taill√©e

## üìÑ Licence

MIT License - voir le fichier [LICENSE](LICENSE) pour plus de d√©tails.

## üÜò Support

- **Issues** : Utiliser GitHub Issues
- **Discussions** : GitHub Discussions
- **Email** : support@shoppingmonitor.com

---

**D√©velopp√© avec ‚ù§Ô∏è pour le monitoring e-commerce** 